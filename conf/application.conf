# Database Configuration - PostgreSQL
db.default.driver=org.postgresql.Driver
db.default.url="jdbc:postgresql://localhost:5432/sentiment_analysis"
db.default.username=sentiment_user
db.default.password="sentiment_pass_2024"

# Connection Pool Settings
db.default.hikaricp.minimumIdle=5
db.default.hikaricp.maximumPoolSize=25
db.default.hikaricp.connectionTimeout=30000
db.default.hikaricp.idleTimeout=600000
db.default.hikaricp.maxLifetime=1800000

# PostgreSQL Specific Settings
db.default.hikaricp.dataSource.cachePrepStmts=true
db.default.hikaricp.dataSource.prepStmtCacheSize=250
db.default.hikaricp.dataSource.prepStmtCacheSqlLimit=2048

# Slick Configuration - PostgreSQL
slick.dbs.default.profile="slick.jdbc.PostgresProfile$"
slick.dbs.default.db.driver="org.postgresql.Driver"
slick.dbs.default.db.url="jdbc:postgresql://localhost:5432/sentiment_analysis"
slick.dbs.default.db.user=sentiment_user
slick.dbs.default.db.password="sentiment_pass_2024"

# Database Migration/Evolution Settings
play.evolutions.enabled=false
play.evolutions.autoApply=false
play.evolutions.autoApplyDowns=false

# Play Configuration
play.http.secret.key="changeme"
# Temporarily disable database module for testing
# play.modules.enabled += "play.api.db.slick.SlickModule"
play.modules.enabled += "modules.CustomModule"

# File Upload Configuration
play.http.parser.maxDiskBuffer=10MB
play.http.parser.maxMemoryBuffer=2MB

# Application Configuration
application.name="Sentiment Analysis NLP"
application.version="1.0.0"

# NLP Configuration
nlp.models.path="models/"
nlp.stanford.annotators="tokenize,ssplit,pos,lemma,sentiment"

# Web Scraping Configuration
scraping.timeout=30000
scraping.retries=3
scraping.user.agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

# Apache Spark Configuration
spark.app.name="Sentiment Analysis with Spark"
spark.master="local[*]"
spark.ui.enabled=true
spark.ui.port=4040
spark.driver.memory="2g"
spark.executor.memory="2g"
spark.sql.shuffle.partitions=4
spark.eventLog.enabled=true
spark.eventLog.dir="file:///tmp/spark-events"
spark.history.fs.logDirectory="file:///tmp/spark-events"
